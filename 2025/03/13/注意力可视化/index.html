
<!DOCTYPE html>
<html lang="Zh-CN">
<head>
    <meta charset="utf-8" />
    <title>注意力可视化 | SharlotAway</title>
    <meta name="author" content="Sharlot Away" />
    <meta name="description" content="" />
    <meta name="keywords" content="" />
    <meta
        name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0"
    />
    <link rel="icon" href="/images/avatar_f.jpg" />
    <link rel="preconnect" href="https://s4.zstatic.net" />
<script src="https://s4.zstatic.net/ajax/libs/vue/3.3.7/vue.global.prod.min.js"></script>
<link rel="stylesheet" href="https://s4.zstatic.net/ajax/libs/font-awesome/6.4.2/css/all.min.css" />
<link rel="preconnect" href="https://fonts.googleapis.cn" />
<link rel="preconnect" href="https://fonts.gstatic.cn" crossorigin />
<link
    rel="stylesheet"
    href="https://fonts.googleapis.cn/css2?family=Fira+Code:wght@400;500;600;700&family=Lexend:wght@400;500;600;700;800;900&family=Noto+Sans+SC:wght@400;500;600;700;800;900&display=swap"
/>
<script> const mixins = {}; </script>

<script src="https://polyfill.alicdn.com/v3/polyfill.min.js?features=default"></script>


<script src="https://s4.zstatic.net/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
<script src="https://s4.zstatic.net/ajax/libs/highlightjs-line-numbers.js/2.8.0/highlightjs-line-numbers.min.js"></script>
<link
    rel="stylesheet"
    href="https://s4.zstatic.net/ajax/libs/highlight.js/11.9.0/styles/github.min.css"
/>
<script src="/js/lib/highlight.js"></script>



<script src="/js/lib/preview.js"></script>









<link rel="stylesheet" href="/css/main.css" />

<meta name="generator" content="Hexo 7.3.0"></head>
<body>
    <div id="layout">
        <transition name="fade">
            <div id="loading" v-show="loading">
                <div id="loading-circle">
                    <h2>LOADING</h2>
                    <p>加载过慢请开启缓存 浏览器默认开启</p>
                    <img src="/images/loading_furina.gif" />
                </div>
            </div>
        </transition>
        <div id="menu" :class="{ hidden: hiddenMenu, 'menu-color': menuColor}">
    <nav id="desktop-menu">
        <a class="title" href="/">
            <span>SHARLOTAWAY</span>
        </a>
        
        <a href="/">
            <i class="fa-solid fa-house fa-fw"></i>
            <span>&ensp;Home</span>
        </a>
        
        <a href="/about/">
            <i class="fa-solid fa-id-card fa-fw"></i>
            <span>&ensp;About</span>
        </a>
        
        <a href="/archives">
            <i class="fa-solid fa-box-archive fa-fw"></i>
            <span>&ensp;Archives</span>
        </a>
        
        <a href="/categories">
            <i class="fa-solid fa-bookmark fa-fw"></i>
            <span>&ensp;Categories</span>
        </a>
        
        <a href="/tags/">
            <i class="fa-solid fa-tags fa-fw"></i>
            <span>&ensp;Tags</span>
        </a>
        
    </nav>
    <nav id="mobile-menu">
        <div class="title" @click="showMenuItems = !showMenuItems">
            <i class="fa-solid fa-bars fa-fw"></i>
            <span>&emsp;SHARLOTAWAY</span>
        </div>
        <transition name="slide">
            <div class="items" v-show="showMenuItems">
                
                <a href="/">
                    <div class="item">
                        <div style="min-width: 20px; max-width: 50px; width: 10%">
                            <i class="fa-solid fa-house fa-fw"></i>
                        </div>
                        <div style="min-width: 100px; max-width: 150%; width: 20%">Home</div>
                    </div>
                </a>
                
                <a href="/about/">
                    <div class="item">
                        <div style="min-width: 20px; max-width: 50px; width: 10%">
                            <i class="fa-solid fa-id-card fa-fw"></i>
                        </div>
                        <div style="min-width: 100px; max-width: 150%; width: 20%">About</div>
                    </div>
                </a>
                
                <a href="/archives">
                    <div class="item">
                        <div style="min-width: 20px; max-width: 50px; width: 10%">
                            <i class="fa-solid fa-box-archive fa-fw"></i>
                        </div>
                        <div style="min-width: 100px; max-width: 150%; width: 20%">Archives</div>
                    </div>
                </a>
                
                <a href="/categories">
                    <div class="item">
                        <div style="min-width: 20px; max-width: 50px; width: 10%">
                            <i class="fa-solid fa-bookmark fa-fw"></i>
                        </div>
                        <div style="min-width: 100px; max-width: 150%; width: 20%">Categories</div>
                    </div>
                </a>
                
                <a href="/tags/">
                    <div class="item">
                        <div style="min-width: 20px; max-width: 50px; width: 10%">
                            <i class="fa-solid fa-tags fa-fw"></i>
                        </div>
                        <div style="min-width: 100px; max-width: 150%; width: 20%">Tags</div>
                    </div>
                </a>
                
            </div>
        </transition>
    </nav>
</div>
<transition name="fade">
    <div id="menu-curtain" @click="showMenuItems = !showMenuItems" v-show="showMenuItems"></div>
</transition>

        <div id="main" :class="loading ? 'into-enter-from': 'into-enter-active'">
            <div class="article">
    <div>
        <h1>注意力可视化</h1>
    </div>
    <div class="info">
        <span class="date">
            <span class="icon">
                <i class="fa-solid fa-calendar fa-fw"></i>
            </span>
            2025/3/13
        </span>
        
        
        <span class="tags">
            <span class="icon">
                <i class="fa-solid fa-tags fa-fw"></i>
            </span>
            
            
            <span class="tag">
                
                <a href="/tags/Visualization/" style="color: #00a596">
                    Visualization
                </a>
            </span>
            
            <span class="tag">
                
                <a href="/tags/Qwen2/" style="color: #ffa2c4">
                    Qwen2
                </a>
            </span>
            
        </span>
        
    </div>
    
    <div class="content" v-pre>
        <p>这篇文章的主要目的是从语言模型开始逐步理解注意力的可视化并最终应用到 <code>llava-onevision-qwen2-0.5b-ov</code> 上以实现从文本到图像的关注。由于使用一些现成的 VLM 可视化工具得到的结果比较惨不忍睹，决定自己从头实现。</p>
<h1 id="1-Qwen2-入门"><a href="#1-Qwen2-入门" class="headerlink" title="1. Qwen2 入门"></a>1. Qwen2 入门</h1><p>以下代码是使用 transformers 加载 Qwen2 模型的代码，为了和 LLaVA 保持一致，选择用 <code>Qwen2ForCasualLM</code> 来代替<code>AutoModelForCausalLM</code>。无法连接到 Huggingface 的话就从<code>hf-mirror</code>把模型下载到本地，然后将 <code>model_name</code> 换成本地的模型权重路径。</p>
<pre><code class="python"># 引入依赖
import torch
from transformers import Qwen2Config, Qwen2Model, Qwen2ForCausalLM, Qwen2Tokenizer
from transformers import AutoModelForCausalLM, AutoTokenizer

# 加载模型和分词器
model_name = &quot;/path/to/your/Qwen2-0.5B-Instruct&quot;  
model = Qwen2ForCausalLM.from_pretrained(
    model_name,
    torch_dtype=torch.bfloat16,
    device_map=&quot;auto&quot;
)
tokenizer = AutoTokenizer.from_pretrained(model_name)
</code></pre>
<p>接下来是定制 <code>prompt</code> 和对话模板进行输出，例如我们提问模型“中国的首都是哪里？”</p>
<pre><code class="python">prompt = &quot;What is the capital of China ?&quot;
messages = [&#123;&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: prompt&#125;]
text = tokenizer.apply_chat_template(
    messages,
    tokenize=False,
    add_generation_prompt=True
)
# 使用分词器转换为词语的序号
model_inputs = tokenizer([text], return_tensors=&quot;pt&quot;).to(model.device)
# 生成响应的序号
generated_ids = model.generate(
    **model_inputs,
    max_new_tokens=128
)
generated_ids = [
    output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)
]
# 解码，由于是 batch，所以返回的是数组
response = tokenizer.batch_decode(generated_ids, skip_special_tokens=False)[0]
</code></pre>
<h2 id="1-1-注意力输出"><a href="#1-1-注意力输出" class="headerlink" title="1.1. 注意力输出"></a>1.1. 注意力输出</h2><p>上述代码使用到了对话模板和解码器生成序列，这是用于文本交互的输入输出方式。为了输出注意力的可视化，需要直接使用前向传播，返回模型的输出，注意力等内容。同样的问题，代码如下：</p>
<pre><code class="python"># 输入文本
text = prompt
inputs = tokenizer(text, return_tensors=&quot;pt&quot;).to(&quot;cuda&quot;)
# 前向传播，并获取注意力权重
with torch.no_grad():
    outputs = model(**inputs, output_attentions=True)  # 关键参数 output_attentions=True
# outputs = model(**input)

# `attentions` 是一个元组，包含每一层的注意力权重
# shape: (num_layers, batch_size, num_heads, seq_len, seq_len)
attentions = outputs.attentions  

# 选择最后一层的注意力权重
# shape: (num_heads, seq_len, seq_len)
last_layer_attention = attentions[-1][0]  
# 对所有注意力头取均值
mean_attention = last_layer_attention.mean(dim=0)  # shape: (seq_len, seq_len)
</code></pre>
<p>使用 <code>output_attention=True</code> 来让模型的前向传播包含注意力，接下来使用 <code>matplotlib</code> 和 <code>seaborn</code> 来输出注意力可视化图。</p>
<blockquote>
<p>  直接分词得到的结果会有很多单词前面有一个符号 Ġ，这是因为在 Qwen 的词表中加入了很多 Ġ+单词组成的新词。这个 Ġ 可以表示这个词是独立的单词，或者表示单词前面有空格，用于更好地解码输出。</p>
</blockquote>
<pre><code class="python"># 可视化
import matplotlib.pyplot as plt
import seaborn as sns

# 这一段单纯去掉了分词符号&quot;Ġ&quot;
token_list = []
for t in tokenizer.convert_ids_to_tokens(inputs[&quot;input_ids&quot;][0]):
    if t.startswith(&quot;Ġ&quot;):
        token_list.append(t[1:])
    else:
        token_list.append(t)

sns.heatmap(
    mean_attention.cpu().to(torch.float16).numpy(),  # 关键修改：转换为 float32
    xticklabels=token_list,
    yticklabels=token_list,
    cmap=&quot;Blues&quot;
)
plt.xlabel(&quot;Attended Token&quot;)
plt.ylabel(&quot;Query Token&quot;)
plt.title(&quot;Qwen2 Last Layer Mean Attention (Across All Heads)&quot;)
plt.show()
</code></pre>
<p>很不巧的是，上面的这段是<code>prompt</code>的单词之间的自注意力，而我们需要的是看输出对输入的注意力。</p>
<p><img src="/2025/03/13/%E6%B3%A8%E6%84%8F%E5%8A%9B%E5%8F%AF%E8%A7%86%E5%8C%96/prompt-visualization.png"></p>
<h2 id="1-2-输出对输入的注意力"><a href="#1-2-输出对输入的注意力" class="headerlink" title="1.2 输出对输入的注意力"></a>1.2 输出对输入的注意力</h2><p>使用 <code>output_attentions</code> 参数输出注意力，将输入输出拼接起来。<code>model()</code> 调用的是前向传播，返回输入序列</p>
<pre><code class="python">inputs = model_inputs
# 生成输出，并获取注意力权重
with torch.no_grad():
    generated_ids = model.generate(
        **inputs,
        max_new_tokens=50,  # 控制生成长度
        return_dict_in_generate=True,  # 关键参数，确保输出包含 attentions
        output_attentions=True  # 关键参数，返回注意力
    )

# 获取所有 token（输入 + 生成的输出）
# full_input_ids = torch.cat([inputs.input_ids, generated_ids.sequences[:, inputs.input_ids.shape[1]:]], dim=1)
full_input_ids = generated_ids.sequences

# 提取注意力
attentions = generated_ids.attentions  # shape: (num_layers, num_heads, seq_len, seq_len)
last_layer_attention = attentions[-2][0].mean(dim=1)  # (batch, num_heads, seq_len, seq_len) -&gt; (batch, seq_len, seq_len)

# 生成完整的 token 列表（输入 + 输出）
token_list = tokenizer.convert_ids_to_tokens(full_input_ids[0])
</code></pre>
<p>绘图代码和上面一样，输出结果为</p>
<p><img src="/2025/03/13/%E6%B3%A8%E6%84%8F%E5%8A%9B%E5%8F%AF%E8%A7%86%E5%8C%96/prompt+output-use_cache.png"></p>
<p>看到只有第一行显示，如果在输出的时候修改参数为 <code>use_cache=False</code> 就可以将其展开，但是是否可以考虑直接将上面的结果作为一个合并的输出。</p>
<p><img src="/2025/03/13/%E6%B3%A8%E6%84%8F%E5%8A%9B%E5%8F%AF%E8%A7%86%E5%8C%96/prompt+output.png"></p>
<p>随后，选择回复前的那个Ċ作为对输入的全局信息的token，输出热图，如下图所示。</p>
<p><img src="/2025/03/13/%E6%B3%A8%E6%84%8F%E5%8A%9B%E5%8F%AF%E8%A7%86%E5%8C%96/C_attn2_prompt.png"></p>
<h2 id="2-LLaVA-OneVision-Qwen2-注意力可视化"><a href="#2-LLaVA-OneVision-Qwen2-注意力可视化" class="headerlink" title="2. LLaVA-OneVision-Qwen2 注意力可视化"></a>2. LLaVA-OneVision-Qwen2 注意力可视化</h2><p>To be continued.</p>

    </div>
    
    
    
    
    
    
    
</div>

            <footer id="footer">
    <div id="footer-wrap">
        <div>
            &copy;
            2025 - 2025 SharlotAway
            <span id="footer-icon">
                <i class="fa-solid fa-font-awesome fa-fw"></i>
            </span>
            &commat;Sharlot Away
        </div>
        <div>
            Based on the <a target="_blank" rel="noopener" href="https://hexo.io">Hexo Engine</a> &amp;
            <a target="_blank" rel="noopener" href="https://github.com/theme-particlex/hexo-theme-particlex">ParticleX Theme</a>
        </div>
        
    </div>
</footer>

        </div>
        
        <transition name="fade">
            <div id="preview" ref="preview" v-show="previewShow">
                <img id="preview-content" ref="previewContent" />
            </div>
        </transition>
        
    </div>
    <script src="/js/main.js"></script>
    
    




    
</body>
</html>
